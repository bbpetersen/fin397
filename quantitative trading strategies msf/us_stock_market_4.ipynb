{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "assisted-glance",
   "metadata": {},
   "source": [
    "# U.S. Stock Market IV: Interest & Debt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests, zipfile, io\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from tiingo import TiingoClient                       \n",
    "tiingo = TiingoClient({'api_key':'XXXX'})\n",
    "\n",
    "import matplotlib.pyplot as plt                        # Basic plot library.\n",
    "plt.style.use('ggplot')                                # Make plots look nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items_from_SEC_files(tags, filename=None):                # Function input: list of tags, optional filename.\n",
    "\n",
    "    directory = 'data/sec/merged/'                                # Read data from here.\n",
    "    filenames = [filename] if filename else os.listdir(directory) # Supplied filename or all files in \"merged\" directory.\n",
    "    filenames = [f for f in filenames if not f.startswith(\".\")]   # Exclude hidden files from file list.\n",
    "\n",
    "    results   = {t:pd.DataFrame() for t in tags}                  # Dictionary of tables (1 table for each tag)\n",
    "\n",
    "    for filename in filenames:                                    # Loop over all files.\n",
    "        print(filename)\n",
    "        data = pd.read_csv(directory+filename, parse_dates=['filed','ddate'])  # Read the file.\n",
    "        \n",
    "        for t in tags:                                            # Loop over all tags.\n",
    "            item  = data[data.tag==t]                             # Select all data for this tag.\n",
    "            short = item.sort_values(['cik','filed','ddate','qtrs'], ascending=[True,True,True,False]) # Samllest qrts.\n",
    "            long  = item.sort_values(['cik','filed','ddate','qtrs'], ascending=[True,True,True,True])  # Largest  qtrs.\n",
    "            short = short.groupby(['cik','filed']).last()[['value','qtrs']]     # One value for each firm and filing.\n",
    "            long  = long .groupby(['cik','filed']).last()[['value','qtrs']]     \n",
    "            short_long = short.join(long, lsuffix='_shortest', rsuffix='_longest') # Put shortest and longest next to each other.\n",
    "            results[t] = results[t].append( short_long )  \n",
    "                        \n",
    "    for t in tags:                                                # Now sort all tables by filing date.\n",
    "        if not results[t].empty: results[t] = results[t].sort_index(level='filed')            \n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "def combine_items(tags, items):\n",
    "    result = items[tags[0]]\n",
    "    for tag in tags[1:]:  result = result.combine_first( items[tag] )\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def calculate_quarterly_annual_values(item):                        # item: table with shortest and longest values and quarters.\n",
    "    result           = pd.DataFrame()                               # Results go here.\n",
    "    all_firms        = item.index.get_level_values('cik').unique()  # All CIKs.\n",
    "    all_filing_dates = pd.read_csv('data/sec/dates/filing_dates.csv', index_col='cik', parse_dates=['filed'])\n",
    "    \n",
    "    for cik in all_firms:                                           # Loop over all firms.  \n",
    "        filing_dates = pd.Series(all_filing_dates.filed[cik])       # All filing dates for this firm.\n",
    "\n",
    "        # Quarterly values:\n",
    "        valuesQ = item.loc[cik].value_shortest.reindex(filing_dates) # Values with shortest reported quarters.\n",
    "        qtrsQ   = item.loc[cik].qtrs_shortest.astype(int)           # Number of quarters for each value.\n",
    "        for date,q in qtrsQ[qtrsQ>1].iteritems():                   # Loop over all dates with > 1 quarters. \n",
    "            previous_values = valuesQ[:date][-q:-1]                 # Example: for q=3 we need to subtract 2 previous quarters.            \n",
    "            if len(previous_values) == q-1:                         # If all previous values available.\n",
    "                valuesQ[date] -= previous_values.sum(skipna=False)  # Subtract previous values to get quarterly value.\n",
    "            else:\n",
    "                valuesQ[date]  = np.nan                  \n",
    "\n",
    "        # Annual values:\n",
    "        valuesA = item.loc[cik].value_longest.reindex(filing_dates) # Values with longest reported quarters.\n",
    "        qtrsA   = item.loc[cik].qtrs_longest.astype(int)            # Number of quarters for each value.\n",
    "        for date,q in qtrsA[qtrsA<4].iteritems():                   # Loop over all dates with < 4 quarters. \n",
    "            previous_values = valuesQ[:date][-4:-q]                 # Example: for q=2 we need to add quarters -3 and -4.\n",
    "            if len(previous_values) == 4-q:                         # If all previous data available.     \n",
    "                valuesA[date] += previous_values.sum(skipna=False)  # Add previous values to get annual values.\n",
    "            else:\n",
    "                valuesA[date]  = np.nan        \n",
    "        \n",
    "        result = result.append( pd.DataFrame({'cik':cik, 'filed':filing_dates, 'valueQ':valuesQ.values, 'valueA':valuesA.values}) )\n",
    "\n",
    "    return result.set_index(['cik','filed'])                        # Return a table with columns 'valueQ' and 'valueA'.\n",
    "\n",
    "\n",
    "\n",
    "def ffill_values(item, dates):                                          \n",
    "    data = item.unstack('cik')\n",
    "    data = data.reindex(dates.union(data.index)).sort_index()           # Add specified dates to index.\n",
    "    filing_dates = pd.read_csv('data/sec/dates/filing_dates.csv', index_col='cik', parse_dates=['filed']).filed\n",
    "    last_filing_date_all_firms = filing_dates.max()                     # Most recent date where at least 1 firm filed.\n",
    "     \n",
    "    for cik in data.columns:                                            # Loop over all firms.\n",
    "        last_filing_date      = pd.Series(filing_dates[cik]).iloc[-1]   # Last date where this firm filed\n",
    "        days_since_last_filed = (last_filing_date_all_firms - last_filing_date).days\n",
    "        last_date_this_firm   = dates[-1] if days_since_last_filed < 120 else last_filing_date\n",
    "        data.loc[:last_date_this_firm, cik].ffill(inplace=True)         # Forward fill all the values.\n",
    "\n",
    "    return data.loc[dates]                                              # Return only specified dates.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-webmaster",
   "metadata": {},
   "source": [
    "Get these tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-fiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_shortTermDebt               = ['ShortTermBorrowing','DebtCurrent']\n",
    "tags_longTermDebtCurrent         = ['LongTermDebtAndCapitalLeaseObligationsCurrent', 'LongTermDebtCurrent']\n",
    "tags_longTermDebtNoncurrent      = ['LongTermDebtAndCapitalLeaseObligations', 'LongTermDebtNoncurrent']\n",
    "tags_interest_expense            = ['InterestExpenseDebt','InterestAndDebtExpense','InterestExpense','InterestIncomeExpenseNonoperatingNet']\n",
    "tags_interest_income             = ['InvestmentIncomeInterest','InterestAndOtherIncome']\n",
    "\n",
    "all_tags = tags_shortTermDebt + tags_longTermDebtCurrent + tags_longTermDebtNoncurrent + tags_interest_expense + tags_interest_income \n",
    "\n",
    "items = get_items_from_SEC_files( all_tags )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-reservoir",
   "metadata": {},
   "outputs": [],
   "source": [
    "items['interest_expense'] = combine_items(tags_interest_expense,  items)\n",
    "items['interest_income']  = combine_items(tags_interest_income,   items)\n",
    "\n",
    "interest_expense = calculate_quarterly_annual_values(items['interest_expense'])\n",
    "interest_income  = calculate_quarterly_annual_values(items['interest_income'])\n",
    "\n",
    "interest_expense[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closing-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "shortTermDebt          = combine_items(tags_shortTermDebt,          items)\n",
    "longTermDebtCurrent    = combine_items(tags_longTermDebtCurrent,    items)\n",
    "longTermDebtNoncurrent = combine_items(tags_longTermDebtNoncurrent, items)\n",
    "\n",
    "shortTermDebt[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-cisco",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save files\n",
    "interest_income        .to_csv('data/sec/items/InterestIncome.csv')\n",
    "interest_expense       .to_csv('data/sec/items/InterestExpense.csv')\n",
    "shortTermDebt          .to_csv('data/sec/items/ShortTermDebt.csv')\n",
    "longTermDebtCurrent    .to_csv('data/sec/items/LongTermDebtCurrent.csv')\n",
    "longTermDebtNoncurrent .to_csv('data/sec/items/LongTermDebtNoncurrent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read files (units: billion dollars)\n",
    "interest_income        = pd.read_csv('data/sec/items/InterestIncome.csv',        parse_dates=['filed'], index_col=['filed','cik'])  / 10**9\n",
    "interest_expense       = pd.read_csv('data/sec/items/InterestExpense.csv',       parse_dates=['filed'], index_col=['filed','cik'])  / 10**9\n",
    "shortTermDebt          = pd.read_csv('data/sec/items/ShortTermDebt.csv',         parse_dates=['filed'], index_col=['filed','cik'])  / 10**9\n",
    "longTermDebtCurrent    = pd.read_csv('data/sec/items/LongTermDebtCurrent.csv',   parse_dates=['filed'], index_col=['filed','cik'])  / 10**9\n",
    "longTermDebtNoncurrent = pd.read_csv('data/sec/items/LongTermDebtNoncurrent.csv',parse_dates=['filed'], index_col=['filed','cik'])  / 10**9\n",
    "\n",
    "operatingIncome        = pd.read_csv('data/sec/items/OperatingIncome.csv',       parse_dates=['filed'], index_col=['filed','cik'])  / 10**9\n",
    "operatingIncome[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-testimony",
   "metadata": {},
   "outputs": [],
   "source": [
    "sic = pd.read_csv('data/sec/attributes/sic.csv', parse_dates=['filed'], index_col=['filed','cik'])\n",
    "sic[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-recovery",
   "metadata": {},
   "source": [
    "Fill the tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "strategic-exchange",
   "metadata": {},
   "outputs": [],
   "source": [
    "trading_days = pd.to_datetime( tiingo.get_dataframe('SPY','2009-04-15').index ).tz_convert(None)\n",
    "\n",
    "interestExpenseQ = ffill_values( interest_expense.valueQ, trading_days )  \n",
    "interestExpenseA = ffill_values( interest_expense.valueA, trading_days )\n",
    "\n",
    "interestIncomeQ = ffill_values( interest_income.valueQ, trading_days )  \n",
    "interestIncomeA = ffill_values( interest_income.valueA, trading_days )\n",
    "\n",
    "operatingIncomeQ = ffill_values( operatingIncome.valueQ, trading_days )  \n",
    "operatingIncomeA = ffill_values( operatingIncome.valueA, trading_days )\n",
    "\n",
    "shortTermDebt          = ffill_values( shortTermDebt.value_shortest,          trading_days )\n",
    "longTermDebtCurrent    = ffill_values( longTermDebtCurrent.value_shortest,    trading_days )\n",
    "longTermDebtNoncurrent = ffill_values( longTermDebtNoncurrent.value_shortest, trading_days )\n",
    "\n",
    "sic = ffill_values(sic.sic, trading_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-jacket",
   "metadata": {},
   "source": [
    "Calculate total debt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-removal",
   "metadata": {},
   "outputs": [],
   "source": [
    "debt = shortTermDebt.add(longTermDebtCurrent, fill_value=0).add(longTermDebtNoncurrent, fill_value=0)\n",
    "\n",
    "debt[-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-island",
   "metadata": {},
   "source": [
    "Historical debt for specific firm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-heading",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = pd.read_csv('data/ticker_symbols/symbols.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "cik = symbols[symbols.ticker==''].index[0]\n",
    "\n",
    "debt[cik].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-studio",
   "metadata": {},
   "source": [
    "Top 10 annual interest expense:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "agricultural-transsexual",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cik</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>3720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>2834.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sic\n",
       "cik         \n",
       "1750  3720.0\n",
       "1800  2834.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sic_current = sic.iloc[-1].to_frame('sic')\n",
    "sic_current[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-jumping",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "annual-bristol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all 6000s\n",
    "codes = sic.div(  ).apply(np.floor)\n",
    "codes[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-plastic",
   "metadata": {},
   "outputs": [],
   "source": [
    "financials = codes[codes==].notnull()\n",
    "financials[-3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-debut",
   "metadata": {},
   "source": [
    "Top 10 financial firms annual interest expense:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-orleans",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "younger-domain",
   "metadata": {},
   "source": [
    "Top 10 non-financial firms annual interest expense:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-protection",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "saved-forty",
   "metadata": {},
   "source": [
    "Total market debt (non-financials):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-enzyme",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-variation",
   "metadata": {},
   "source": [
    "Total quarterly interest expense (non-financials):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-account",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "herbal-turtle",
   "metadata": {},
   "source": [
    "Interest expense relative to debt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-transition",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_interestExpsense = \n",
    "total_debt             = \n",
    "\n",
    "(total_interestExpsense*4/total_debt)['2013':].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-bennett",
   "metadata": {},
   "source": [
    "Operating income relative to interest expense:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-difference",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_operatingIncome = operatingIncomeQ[~financials].sum('columns')\n",
    "\n",
    "(total_operatingIncome/total_interestExpsense)['2012':].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-nature",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-mounting",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
