{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and Merge all SEC Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We download SEC company filing data from this website: https://www.sec.gov/dera/data/financial-statement-and-notes-data-set.html \n",
    "\n",
    "\n",
    "This program will generate the following directory (folder) structure:\n",
    "- inside current directory (where you run this notebook): folder \"data\"\n",
    "- inside data folder: folder \"sec\"\n",
    "- inside sec folder: folder \"downloads\" and folder \"merged\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import these libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests, zipfile, io\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our download function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(period):\n",
    "    url = 'https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/'+period+'_notes.zip'\n",
    "    \n",
    "    unzip_folder_name = 'data/sec/downloads/' + period                           # Where to put contents of unzipped file  \n",
    "    \n",
    "    r = requests.get(url)\n",
    "    if r.ok:                                                                     # If download worked\n",
    "        print('Downloaded:', url, 'to:', unzip_folder_name)\n",
    "        Path(unzip_folder_name).mkdir(parents=True, exist_ok=True)               # Make the folder where we unzip the file to   \n",
    "        z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "        z.extractall(members=['sub.tsv','num.tsv'], path=unzip_folder_name)      # Unzip file to the folder we just made\n",
    "    else:\n",
    "        print('File not found:', period)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you previously had trouble downloading the files, and you are worried about running out of space:\n",
    "1. delete all files in your \"downloads\" folder\n",
    "1. empty your trash to make sure that memory is free\n",
    "1. check available memory, you need about 40 GB (you can delete the files later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now download the **most recent file** (you can do this every month, for example in May, dowload the April file with '2021_04'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2021_03_notes.zip to: data/sec/downloads/2021_03\n"
     ]
    }
   ],
   "source": [
    "download_file('2021_03')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now download **all previous files** from 2010 to 2021-2:     \n",
    "(later years have larger file sizes, so the downloads will start fast and then slow down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2009q2_notes.zip to: data/sec/downloads/2009q2\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2009q3_notes.zip to: data/sec/downloads/2009q3\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2009q4_notes.zip to: data/sec/downloads/2009q4\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2010q1_notes.zip to: data/sec/downloads/2010q1\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2010q2_notes.zip to: data/sec/downloads/2010q2\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2010q3_notes.zip to: data/sec/downloads/2010q3\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2010q4_notes.zip to: data/sec/downloads/2010q4\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2011q1_notes.zip to: data/sec/downloads/2011q1\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2011q2_notes.zip to: data/sec/downloads/2011q2\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2011q3_notes.zip to: data/sec/downloads/2011q3\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2011q4_notes.zip to: data/sec/downloads/2011q4\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2012q1_notes.zip to: data/sec/downloads/2012q1\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2012q2_notes.zip to: data/sec/downloads/2012q2\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2012q3_notes.zip to: data/sec/downloads/2012q3\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2012q4_notes.zip to: data/sec/downloads/2012q4\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2013q1_notes.zip to: data/sec/downloads/2013q1\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2013q2_notes.zip to: data/sec/downloads/2013q2\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2013q3_notes.zip to: data/sec/downloads/2013q3\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2013q4_notes.zip to: data/sec/downloads/2013q4\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2014q1_notes.zip to: data/sec/downloads/2014q1\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2014q2_notes.zip to: data/sec/downloads/2014q2\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2014q3_notes.zip to: data/sec/downloads/2014q3\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2014q4_notes.zip to: data/sec/downloads/2014q4\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2015q1_notes.zip to: data/sec/downloads/2015q1\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2015q2_notes.zip to: data/sec/downloads/2015q2\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2015q3_notes.zip to: data/sec/downloads/2015q3\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2015q4_notes.zip to: data/sec/downloads/2015q4\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2016q1_notes.zip to: data/sec/downloads/2016q1\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2016q2_notes.zip to: data/sec/downloads/2016q2\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2016q3_notes.zip to: data/sec/downloads/2016q3\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2016q4_notes.zip to: data/sec/downloads/2016q4\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2017q1_notes.zip to: data/sec/downloads/2017q1\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2017q2_notes.zip to: data/sec/downloads/2017q2\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2017q3_notes.zip to: data/sec/downloads/2017q3\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2017q4_notes.zip to: data/sec/downloads/2017q4\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2018q1_notes.zip to: data/sec/downloads/2018q1\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2018q2_notes.zip to: data/sec/downloads/2018q2\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2018q3_notes.zip to: data/sec/downloads/2018q3\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2018q4_notes.zip to: data/sec/downloads/2018q4\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2019q1_notes.zip to: data/sec/downloads/2019q1\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2019q2_notes.zip to: data/sec/downloads/2019q2\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2019q3_notes.zip to: data/sec/downloads/2019q3\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2019q4_notes.zip to: data/sec/downloads/2019q4\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2020q1_notes.zip to: data/sec/downloads/2020q1\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2020q2_notes.zip to: data/sec/downloads/2020q2\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2020q3_notes.zip to: data/sec/downloads/2020q3\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2020_10_notes.zip to: data/sec/downloads/2020_10\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2020_11_notes.zip to: data/sec/downloads/2020_11\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2020_12_notes.zip to: data/sec/downloads/2020_12\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2021_01_notes.zip to: data/sec/downloads/2021_01\n",
      "Downloaded: https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2021_02_notes.zip to: data/sec/downloads/2021_02\n",
      "Download finished!\n"
     ]
    }
   ],
   "source": [
    "for year in [2009]:                          # Get the quarterly files for 2009\n",
    "    for quarter in [2,3,4]:\n",
    "        period = str(year)+'q'+str(quarter)\n",
    "        download_file(period)\n",
    "\n",
    "for year in range(2010,2020):                # Get the quarterly files 2010 - 2019\n",
    "    for quarter in [1,2,3,4]:\n",
    "        period = str(year)+'q'+str(quarter)\n",
    "        download_file(period)\n",
    "        \n",
    "for year in [2020]:                          # Get the quarterly files for 2020\n",
    "    for quarter in [1,2,3]:\n",
    "        period = str(year)+'q'+str(quarter)\n",
    "        download_file(period)        \n",
    "        \n",
    "for year in [2020]:                          # Get the monthly files for 2020\n",
    "    for month in [10,11,12]:\n",
    "        period = str(year)+'_'+str(month)\n",
    "        download_file(period)\n",
    "                \n",
    "for year in [2021]:                          # Get the monthly files for 2021\n",
    "    for month in [1,2]:\n",
    "        period = str(year)+'_0'+str(month) if month<10 else str(year)+'_'+str(month)\n",
    "        download_file(period)      \n",
    "        \n",
    "print('Download finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use this function to merge all the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sec_files(folder):\n",
    "    \n",
    "    keep_these_columns = ['cik','sic','countryinc','tag','filed','ddate','qtrs','value']\n",
    "    keep_these_tags_with_segments = ['EntityCommonStockSharesOutstanding','CommonStockSharesOutstanding']\n",
    "\n",
    "    filings = pd.read_table('data/sec/downloads/'+folder+'/sub.tsv')\n",
    "    numbers = pd.read_table('data/sec/downloads/'+folder+'/num.tsv', encoding='ISO-8859-1', error_bad_lines=False) \n",
    "\n",
    "    filings = filings[filings.form.isin(['10-Q','10-K']) & filings.cik.notnull()]\n",
    "    numbers = numbers[(numbers.dimh=='0x00000000') | numbers.tag.isin(keep_these_tags_with_segments)]\n",
    "\n",
    "    merged = numbers.merge(filings, on='adsh', how='inner').set_index('adsh')[keep_these_columns]\n",
    "\n",
    "    merged['filed'] = pd.to_datetime(merged.filed, format='%Y%m%d', errors='coerce')   \n",
    "    merged['ddate'] = pd.to_datetime(merged.ddate, format='%Y%m%d', errors='coerce')    \n",
    "    \n",
    "    return merged[merged.filed.notnull() & merged.ddate.notnull()].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge **all files** in your downloads folder (ignore the warning messages):     \n",
    "(this will take a while)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge: 2009q1\n",
      "Merge: 2009q2\n",
      "Merge: 2009q3\n",
      "Merge: 2009q4\n",
      "Merge: 2010q1\n",
      "Merge: 2010q2\n",
      "Merge: 2010q3\n",
      "Merge: 2010q4\n",
      "Merge: 2011q1\n",
      "Merge: 2011q2\n",
      "Merge: 2011q3\n",
      "Merge: 2011q4\n",
      "Merge: 2012q1\n",
      "Merge: 2012q2\n",
      "Merge: 2012q3\n",
      "Merge: 2012q4\n",
      "Merge: 2013q1\n",
      "Merge: 2013q2\n",
      "Merge: 2013q3\n",
      "Merge: 2013q4\n",
      "Merge: 2014q1\n",
      "Merge: 2014q2\n",
      "Merge: 2014q3\n",
      "Merge: 2014q4\n",
      "Merge: 2015q1\n",
      "Merge: 2015q2\n",
      "Merge: 2015q3\n",
      "Merge: 2015q4\n",
      "Merge: 2016q1\n",
      "Merge: 2016q2\n",
      "Merge: 2016q3\n",
      "Merge: 2016q4\n",
      "Merge: 2017q1\n",
      "Merge: 2017q2\n",
      "Merge: 2017q3\n",
      "Merge: 2017q4\n",
      "Merge: 2018q1\n",
      "Merge: 2018q2\n",
      "Merge: 2018q3\n",
      "Merge: 2018q4\n",
      "Merge: 2019q1\n",
      "Merge: 2019q2\n",
      "Merge: 2019q3\n",
      "Merge: 2019q4\n",
      "Merge: 2020_10\n",
      "Merge: 2020_11\n",
      "Merge: 2020_12\n",
      "Merge: 2020q1\n",
      "Merge: 2020q2\n",
      "Merge: 2020q3\n",
      "Merge: 2021_01\n",
      "Merge: 2021_02\n",
      "Merge: 2021_03\n",
      "Merging finished!\n"
     ]
    }
   ],
   "source": [
    "Path('data/sec/merged').mkdir(parents=True, exist_ok=True)              # Make the folder where we save the marged file.  \n",
    "  \n",
    "for folder in sorted(os.listdir('data/sec/downloads/')):                # Loop over all folders in directory \"downloads\".  \n",
    "    if not folder.startswith(\".\"):                                      # Exclude hidden files from file list.\n",
    "        print('Merge:',folder)\n",
    "        merged = merge_sec_files(folder)                                # Generate the merged table.\n",
    "        merged.to_csv('data/sec/merged/'+folder+'.csv', index=False)    # Save the merged table.    \n",
    "    \n",
    "print('Merging finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have all the merged files in the \"merged\" folder. To free up memory, you can now:\n",
    "1. delete all files in \"downloads\" folder\n",
    "1. empty trash\n",
    "\n",
    "You need to keep  all the merged files (but they only take about 8 GB)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now collect the dates of all filings from the merge files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_filing_dates(filename=None):                          # Function input: optional filename.\n",
    "\n",
    "    directory = 'data/sec/merged/'                                # Read data from here.\n",
    "    filenames = [filename] if filename else os.listdir(directory) # Supplied filename or all files in \"merged\" directory.\n",
    "    filenames = [f for f in filenames if not f.startswith(\".\")]   # Exclude hidden files from file list.\n",
    "    \n",
    "    results   = pd.DataFrame()                                    # Results will be appended to this table.\n",
    "\n",
    "    for filename in filenames:                                    # Loop over all files.\n",
    "        data    = pd.read_csv(directory+filename, parse_dates=['filed','ddate'])  # Read the file.        \n",
    "        results = results.append( data.groupby(['cik','filed'],as_index=False).first()[['cik','filed']] )\n",
    "    \n",
    "    return results.sort_values(['cik','filed']).set_index('cik')\n",
    "\n",
    "\n",
    "\n",
    "Path('data/sec/dates').mkdir(parents=True, exist_ok=True)          # Make the folder where we save the filing dates.  \n",
    "\n",
    "filing_dates = get_all_filing_dates()\n",
    "filing_dates.to_csv('data/sec/dates/filing_dates.csv')             # Save the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now every month:\n",
    "1. download the lastest folder (once available on SEC website)\n",
    "1. merge the files\n",
    "1. (delete the downloaded folder if you need space)\n",
    "1. update the filing dates\n",
    "\n",
    "For example do this in early May 2021 (check the SEC website to see if the file is available):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: 2021_04\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File data/sec/downloads/2021_04/sub.tsv does not exist: 'data/sec/downloads/2021_04/sub.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a8859c373b59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m                                           \u001b[0;31m# Dowload the newest data from SEC.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmerged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_sec_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m                                \u001b[0;31m# Generate the merged table.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmerged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/sec/merged/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# Save the merged table.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-7843d4bd1858>\u001b[0m in \u001b[0;36mmerge_sec_files\u001b[0;34m(folder)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mkeep_these_tags_with_segments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'EntityCommonStockSharesOutstanding'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'CommonStockSharesOutstanding'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mfilings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/sec/downloads/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/sub.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mnumbers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/sec/downloads/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/num.tsv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ISO-8859-1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File data/sec/downloads/2021_04/sub.tsv does not exist: 'data/sec/downloads/2021_04/sub.tsv'"
     ]
    }
   ],
   "source": [
    "folder = '2021_04'\n",
    "\n",
    "download_file(folder)                                           # Dowload the newest data from SEC.\n",
    "\n",
    "merged = merge_sec_files(folder)                                # Generate the merged table.\n",
    "merged.to_csv('data/sec/merged/'+folder+'.csv', index=False)    # Save the merged table. \n",
    "\n",
    "filing_dates = get_all_filing_dates()                           # Get all filing dates.\n",
    "filing_dates.to_csv('data/sec/dates/filing_dates.csv')          # Save the filing dates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it!           "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
